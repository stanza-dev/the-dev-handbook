---
source_course: "redis-caching"
source_lesson: "redis-caching-pipelining"
---

# Pipelining for Batch Operations

Pipelining dramatically improves performance when executing multiple Redis commands by reducing network round-trips.

## The Network Latency Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Without Pipelining (3 commands = 3 round-trips):          â”‚
â”‚                                                             â”‚
â”‚  Client â†’ GET key1 â†’ Server â†’ Response (~1ms)              â”‚
â”‚  Client â†’ GET key2 â†’ Server â†’ Response (~1ms)              â”‚
â”‚  Client â†’ GET key3 â†’ Server â†’ Response (~1ms)              â”‚
â”‚  Total: ~3ms                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  With Pipelining (3 commands = 1 round-trip):              â”‚
â”‚                                                             â”‚
â”‚  Client â†’ [GET key1, GET key2, GET key3] â†’ Server          â”‚
â”‚  Client â† [response1, response2, response3] â† Server       â”‚
â”‚  Total: ~1ms (3x faster!)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Implementation

### Python Example

```python
import redis
import time

r = redis.Redis()

# Without pipeline - 1000 round-trips
start = time.time()
for i in range(1000):
    r.set(f'key:{i}', f'value:{i}')
print(f"Without pipeline: {time.time() - start:.3f}s")
# ~1.5 seconds

# With pipeline - 1 round-trip
start = time.time()
pipe = r.pipeline(transaction=False)
for i in range(1000):
    pipe.set(f'key:{i}', f'value:{i}')
pipe.execute()
print(f"With pipeline: {time.time() - start:.3f}s")
# ~0.015 seconds (100x faster!)
```

### Batch Size Optimization

```python
def bulk_operation(keys, batch_size=1000):
    """Process keys in optimal batch sizes"""
    for i in range(0, len(keys), batch_size):
        batch = keys[i:i + batch_size]
        pipe = r.pipeline(transaction=False)
        
        for key in batch:
            pipe.get(key)
        
        results = pipe.execute()
        yield from zip(batch, results)
```

## Pipeline vs Transaction

```python
# Pipeline only (no atomicity, best performance)
pipe = r.pipeline(transaction=False)

# Pipeline with transaction (MULTI/EXEC wrapper)
pipe = r.pipeline()  # transaction=True by default
```

| Mode | Atomicity | Performance | Use Case |
|------|-----------|-------------|----------|
| transaction=False | No | Best | Independent reads/writes |
| transaction=True | Yes | Good | Related operations |

## Cache Warming with Pipelining

```python
def warm_cache(keys_to_warm, fetch_func):
    """Pre-populate cache efficiently"""
    # Check which keys are missing
    pipe = r.pipeline(transaction=False)
    for key in keys_to_warm:
        pipe.exists(key)
    
    exists = pipe.execute()
    missing = [k for k, e in zip(keys_to_warm, exists) if not e]
    
    if not missing:
        return
    
    # Fetch data for missing keys
    data = fetch_func(missing)
    
    # Populate cache in batch
    pipe = r.pipeline(transaction=False)
    for key, value in zip(missing, data):
        pipe.set(key, value, ex=300)
    pipe.execute()
    
    print(f"Warmed {len(missing)} cache entries")
```

ðŸ“– [Redis Pipelining](https://redis.io/docs/latest/develop/use/pipelining/)

## Resources

- [Redis Pipelining](https://redis.io/docs/latest/develop/use/pipelining/) â€” Guide to Redis pipelining

---

> ðŸ“˜ *This lesson is part of the [High-Performance Caching Strategies](https://stanza.dev/courses/redis-caching) course on [Stanza](https://stanza.dev) â€” the IDE-native learning platform for developers.*